# Generative AI Policy

This document outlines the principles, rules, and processes governing the use of Generative AI (GAI) tools and serves as a foundation for responsible GAI integration into [Company]'s operations.

The purpose of this policy is to provide clear guidance on the ethical, safe, and effective use of Generative AI (GAI) tools by team members at [Company]. As GAI technologies continue to evolve, we aim to:

- Ensure that GAI tools support and enhance human skills, rather than replace them.
- Protect company, client, and sensitive data from misuse.
- Promote transparency, accountability, and ethical use in all GAI-assisted workflows.
- Minimize risks associated with GAI tools, such as inaccurate outputs, security vulnerabilities, or ethical concerns.
- Maintain the trust of our clients and team members in all aspects of our work.

This policy applies to all [Company] employees and contractors, as well as any other individuals who use GAI tools in the context of [Company]'s business operations, client work, or internal projects.

## Definitions

- **Artificial Intelligence or AI:** As per 15 U.S.C. 9401(3), a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.

- **AI model:** a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.

- **Generative AI (GAI):** The class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content, including images, videos, audio, and text.
  - GAI includes text-based models used by generative AI chatbots such as ChatGPT, Google Gemini, and Anthropic's Claude. These models may also be integrated into other tools used at [Company], such as Jira, Confluence, Google Workspace, and Hubspot.
  - GAI also includes image, voice, and video generation models such as DALL-E, Adobe Firefly, Sora, ElevenLabs, and tools that integrate those models.

- **Model Stability:** The reliability of an AI tool's output across different datasets or under varying conditions. Typically, established models tend to be more stable than experimental ones.

## General Principles

[Company] is conscious of the ethical and environmental challenges posed by GAI and prioritizes safety, ethics, and environmental sustainability whenever possible. This policy builds on several core principles.

### Human oversight

GAI tools must be treated as collaborative assistants to enhance human capabilities. They're not substitutes for human decision-making, judgment, or accountability. Team members must be able to explain and justify the use of GAI tools and the rationale behind any outputs generated with their assistance. All GAI outputs must undergo human review to ensure they meet [Company]'s quality standards and ethical guidelines.

### Accountability

Use of or consultation with GAI should be treated similarly to receiving assistance from another person. Team members are fully accountable for the quality, substantial completion, and outcome of GAI-assisted work.

### Data privacy and security

Third-party AI tools must not use company or client data to train their models. Team members should not provide AI tools with any more data than necessary to achieve desired results. Sensitive data should be anonymized to safeguard confidentiality. [Company] may use company or client data to train its own models as necessary and appropriate, with the approval of [Company] management.

### Transparency

GAI usage in workflows involving sensitive client data must be transparent to clients. Before using GAI on a project, team members must review client-specific GAI policies and inform the client of GAI usage if applicable. Teams must follow client policies and guidelines around the use of GAI tools when those policies are more stringent than [Company]'s guidelines.

### Environmental responsibility

We are mindful of the environmental impact of generative AI tools. We commit to choosing environmentally responsible AI options and considering sustainability in our technology decisions.

### Risk Awareness and mitigation

We acknowledge the risks associated with AI tools, including:

- Hallucinations: GAI tools may produce incorrect, unreliable, or fabricated information.
- Data Leaks: Improper use of GAI tools may expose sensitive data.
- Bias: GAI outputs reflect bias in the training data or algorithms.

To address these risks, we will:

- Provide resources and training on safe, responsible, and effective GAI usage.
- Promote awareness of GAI limitations and encourage team members to exercise sound human judgment when interpreting GAI outputs.
- Only use authorized GAI tools for client work.

### Responsible and compliant usage

GAI tools cannot be used to generate or modify content in ways that harm others, violate federal or state law, or otherwise violate company policy.

## Prerequisites for using GAI tools

- Only authorized GAI tools can be used for client work. Examples include:
  - Generating, evaluating, or analyzing code, including snippets or samples, included in any in-progress or complete client deliverables
  - Evaluating or analyzing any content provided by a client, including site databases, PDFs, and other documents
  - Generating, evaluating, or analyzing content that is considered part of our work product or client deliverable, including working documents, reports, virtual whiteboards, etc.
  - Generating images or videos that are provided in client deliverables, such as audience personas

- Team members may use non-authorized GAI tools for personal skill-building and experimentation, provided such usage does not involve client or proprietary company data and is aligned with organizational goals and policies. Examples include:
  - Experimenting to learn the capabilities of new GAI models
  - Developing new products that leverage GAI models, with the knowledge and consent of the Systems and Infrastructure team (see "Authorized GAI tools and vendors")
  - Generating, evaluating, or analyzing publicly available or personal data for professional development purposes
  - Using a GAI as a personal coach
  - Developing sales and marketing materials for [Company]
  - Developing internally-facing company documentation and communication

- [Company] will disclose the use of GAI tools in its contracts. Before utilizing GAI tools for client work, team members must:
  - Review any relevant Systems & Infrastructure documentation.
  - Discuss the proposed use of a GAI tool with the project team and relevant team leads to ensure alignment with project objectives and best practices.

- [Company] team members are responsible for reviewing and respecting any GAI policies required by the client organization.
  - If the client has a specific GAI policy or guidelines, team members must carefully review and adhere to these requirements.
  - Ensure that any GAI tool usage complies with the client's data handling and privacy requirements.
  - If a client's contract prohibits the use of GAI tools, this will be shared with the project team, who will be responsible for developing the necessary mitigations.
  - When working with federal government clients, [Company] will abide by relevant agency policies and regulations.

## How to use GAI at [Company]

- GAI tools may be used to assist with tasks such as research, drafting, ideation, review of data, and code development.
  - GAI outputs may be used as a foundation or support, not as a final product. For example, GAI may assist with drafting or reviewing work but requires human oversight and refinement before completion.
  - GAI tools may not substantially generate core deliverables from end-to-end, such as production-ready code, a final report, or major design components.
  - Before incorporating GAI into project work, team members must review any relevant client GAI usage policy. Client policies may impose additional restrictions on how GAI-generated outputs can be used.

- Team members are fully accountable for the quality and accuracy of any work produced with AI assistance. To ensure accountability, all GAI-generated outputs must undergo thorough human review before being delivered or incorporated into any client deliverables.
  - GAI outputs must be critically evaluated for accuracy, relevance, and appropriateness.
  - GAI models are trained on human-generated data, which may contain biases. Team members must remain vigilant and correct any biases or inaccuracies in GAI-generated content.
  - GAI outputs must be reviewed to ensure they meet the highest standards of quality and professionalism.

- Transparency and explainability
  - Team members must be able to explain and justify the use of GAI in their work, ensuring transparency and alignment with project goals.
  - [Company] team members should always be open and transparent with their team and the client about their use of GAI and how it was used to assist with their work.
  - While it is not necessary for team members to include attribution when GAI has been used in an incidental way (e.g., copyediting), substantial use of GAI in a work product (e.g. to generate code, reports, or analyses) should be documented. This documentation should include specific models and prompts used in case someone else wants to reproduce or extend the results.

- When utilizing GAI tools, team members must adhere to the principle of data minimization. This means sharing only the strictly necessary information with the GAI system to achieve the desired outcome.

- Prohibited usage
  - GAI tools shall not be used in any way that violates consent or the human rights of others. This includes, but is not limited to, the creation of nonconsensual image, voice, or video deepfakes.
  - GAI tools shall not be used to create or modify content in a manner that is inauthentic or deceptive.
  - GAI tools shall not be used to create content that is illegal or otherwise violates company policies.

- Prohibited data
  - Personally Identifiable Information (PII): Sharing PII with GAI tools is prohibited. PII includes any information that can be used to directly or indirectly identify an individual, such as names, addresses, social security numbers, and biometric data.
  - Protected Health Information (PHI): Sharing PHI with GAI tools is also prohibited. PHI is any information that can be used to identify an individual and relates to their past, present, or future physical or mental health condition.

- In addition to specific GAI policies, tool usage must comply with all other relevant company policies, including but not limited to those related to data privacy, security, and intellectual property.

## Authorized GAI tools and vendors

- The Software and Infrastructure Team (S&I) is responsible for evaluating and recommending what GAI tools and vendors are authorized for use at [Company]. The S&I team may seek the advice and consultation of the AI Working Group as part of its decision making process:
  - Each GAI vendor will undergo a risk assessment. This risk assessment will be updated periodically by S&I.
  - S&I maintains a list of [authorized tools]
  - GAI features integrated into existing company tools (Miro, Google Workspace, Jira, Confluence, Adobe Creative Suite, macOS, etc.) will be reviewed by S&I as they become available. In general, these company tools are considered authorized for use unless S&I determines otherwise.
  - S&I will inform team members if any available GAI tools are not authorized for use.
  - Team members may request new GAI tools via the [Company] Help Desk following the standard process for requesting new tools.

- GAI tool and vendor evaluation guidelines:
  - GAI models for everyday use should be stable and follow industry-standard best practices for safety, ethics, and environmental sustainability.
    - S&I may make exceptions for experimental models and usage on a case-by-case basis. These exceptions will be documented as part of the [Company] Help Desk request process.
  - Where possible, [Company] will avoid using tools that create vendor dependencies.
  - Where possible, GAI tools should utilize [Company]'s existing security infrastructure, such as standardized logins. Access to specific tools may be restricted based on role and project requirements.

- Team members who have reason to believe company or client data may have been compromised by an AI tool or vendor must file an incident report via [Company] Help Desk. Security events will be reviewed and addressed by S&I following [Company]'s standard incident response process.

## HR and legal compliance

- [Company]'s use of GAI tools is subject to laws that have jurisdiction in [Company Home State] and other places where [Company] has employees or does business.
  - Compliance concerns should be raised to [Company]'s Chief of Staff or CEOs.
[For Illinois firms only]
- [Company] is subject to the requirements of the Illinois Human Rights Act with regard to AI and GAI usage. [Company] employees are hereby notified that AI and/or GAI may be used in connection with employment decisions following regulations and guidance issued by the Illinois Department of Human Rights (DHR).
  - Effective on or before January 1, 2026, AI and GAI tools will not be used in connection with "recruitment, hiring, promotion, renewal of employment, selection for training or apprenticeship, discharge, discipline, tenure, or the terms, privileges, or conditions of employment" in a way that subjects an employee to any discrimination based on either their protected class(es) or their zip code.
  - The Illinois Human Rights Act defines AI as "a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments". Generative AI is defined as "an automated computing system that, when prompted with human prompts, descriptions, or queries, can produce outputs that simulate human-produced content, including, but not limited to, the following: 1) textual outputs, such as short answers, essays, poetry, or longer compositions or answers; 2) image outputs, such as fine art, photographs, conceptual art, diagrams, and other images; 3) multimedia outputs, such as audio or video in the form of compositions, songs, or short-form or long-form audio or video; and 4) other content that would be otherwise produced by human means"

- Notwithstanding the above, GAI tools may be used to assist with the development of:
  - HR-related communications, such as memos and policy updates
  - Hiring notices
  - Promotion packets created by employees
  - Coaching documentation, leveling reviews, and performance improvement requests

- All hiring and HR-related material created with the assistance of GAI tools (and any updates thereto) must be subjected to human review, with a particular focus on identifying and addressing any potential biases introduced by the GAI model.

- GAI tools will not be used in place of humans to screen or interview prospective employees; however, assistive tools such as notetakers can be used in the interview and hiring process as long as these are disclosed to the applicant.

## Stakeholders

Key stakeholders responsible for overseeing and implementing this policy include:

- **Executive Leadership**: Ensures alignment with company strategy and legal requirements.
- **Software & Infrastructure Team**: Evaluates and approves AI tools, maintains vendor relationships, and oversees security.
- **AI Working Group**: Provides advice and consultation to the Software & Infrastructure Team, provides support and resources to [Company] team members.
- **Project Teams & Client Leads**: Ensure transparency and client alignment regarding AI use.

## Updates

This policy will be reviewed at least once per calendar year by [Company]'s AI Working Group and the Systems and Infrastructure Group. The AI Working Group will provide advice and consultation to the Systems and Infrastructure Group, who will be responsible for recommending changes and updates. Changes and updates will be reviewed and approved by [Company] management or their designates. Reviews may occur more frequently if needed because of changes in law or technology.

[Company] team members will be made aware of new and updated [Company]-wide AI policies through standard communications channels (All-Company meetings, Slack, email, etc.). New and current team members will be asked to indicate they have read and understand those policies.
